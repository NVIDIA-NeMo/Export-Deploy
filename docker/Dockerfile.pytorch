# Copyright (c) 2025, NVIDIA CORPORATION. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

FROM nvcr.io/nvidia/pytorch:25.06-py3
WORKDIR /workspace
COPY . .
ARG INFERENCE_FRAMEWORK
ENV PATH="/root/.local/bin:$PATH"
ENV UV_PROJECT_ENVIRONMENT=/opt/venv
ENV PATH="$UV_PROJECT_ENVIRONMENT/bin:$PATH"
ENV UV_LINK_MODE=copy
# ENV CUDA_HOME=/usr/local/cuda
# ENV PATH=$PATH:$CUDA_HOME/bin
ENV LD_LIBRARY_PATH=/opt/hpcx/ucx/lib:/usr/local/cuda/lib64:$LD_LIBRARY_PATH
ENV VLLM_USE_STANDALONE_COMPILE=0
# ENV TORCH_CUDA_ARCH_LIST="6.0;6.1;7.0;7.5;8.0;8.6;9.0"

RUN bash -ex <<"EOF"
    export PAT=$(cat /run/secrets/GH_TOKEN)
    bash docker/common/install.sh --base-image pytorch --use-uv --inference-framework $INFERENCE_FRAMEWORK
    uv cache prune --ci
EOF
