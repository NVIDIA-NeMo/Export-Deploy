# Copyright (c) 2026, NVIDIA CORPORATION. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

ARG BASE_IMAGE=nvcr.io/nvidia/pytorch:25.11-py3
FROM ${BASE_IMAGE} AS base

ENV PIP_NO_CACHE_DIR=1
ENV DEBIAN_FRONTEND=noninteractive
ENV VLLM_USE_STANDALONE_COMPILE=0

WORKDIR /opt

##############################################################################
##
## VLLM wheel
##
##############################################################################

FROM base AS vllm_wheel

ARG VLLM_VERSION
ARG MAX_JOBS=4

WORKDIR /src/vllm

# Build vllm
RUN git clone https://github.com/vllm-project/vllm.git . && \
    echo "Building vLLM version: $VLLM_VERSION" && \
    git checkout $VLLM_VERSION && \
    python use_existing_torch.py && \
    pip install -r requirements/build.txt && \
    sed -i "/xgrammar/d" requirements/common.txt && \
    pip wheel --no-deps --no-build-isolation -v .

##############################################################################
##
## TRT-LLM repo
##
##############################################################################

FROM base AS trtllm_repo

ARG TRT_LLM_COMMIT
ARG NVRTC_VER
ARG TRT_VER

WORKDIR /src/tensorrt_llm

RUN apt-get update && apt-get install -y --no-install-recommends git-lfs && \
    rm -rf /var/lib/apt/lists/* && \
    apt-get clean

RUN git clone https://github.com/NVIDIA/TensorRT-LLM.git . && \
    git pull && \
    git fetch origin $TRT_LLM_COMMIT && \
    git checkout -f FETCH_HEAD && \
    git submodule update --init --recursive && \
    git lfs install && git lfs pull && \
    sed -i "s/NVRTC_VER=\"[^\"]*\"/NVRTC_VER=\"${NVRTC_VER}\"/g" /src/tensorrt_llm/docker/common/install_tensorrt.sh && \
    sed -i "s/CUDA_RUNTIME==\"[^\"]*\"/CUDA_RUNTIME==\"${NVRTC_VER}\"/g" /src/tensorrt_llm/docker/common/install_tensorrt.sh && \
    sed -i "/triton/d" requirements.txt && \
    sed -i "s/tensorrt~=[0-9.]*/tensorrt~=${TRT_VER}/g" requirements.txt && \
    sed -i "/flashinfer-python/d" requirements.txt && \
    sed -i "/nvidia-nccl-cu13/d" requirements.txt && \
    sed -i "/nvidia-cuda-nvrtc/d" requirements.txt && \
    sed -i "/torch/d" requirements.txt && \
    sed -i "/xgrammar/d" requirements.txt;

##############################################################################
##
## TRT-LLM builder
##
##############################################################################

FROM vllm_wheel AS trtllm_builder

ARG TRT_VER
ARG CUDA_VER
ARG CUDNN_VER
ARG NCCL_VER
ARG CUBLAS_VER
ARG TRT_LLM_COMMIT
RUN --mount=type=bind,from=trtllm_repo,source=/src/tensorrt_llm/docker/common,target=tensorrt_llm/docker/common/ \
    apt-get remove --purge -y libnvinfer* tensorrt* || true && \
    pip3 uninstall -y tensorrt || true && \
    bash tensorrt_llm/docker/common/install_tensorrt.sh \
    --TRT_VER=${TRT_VER} \
    --CUDA_VER=${CUDA_VER} \
    --CUDNN_VER=${CUDNN_VER} \
    --NCCL_VER=${NCCL_VER} \
    --CUBLAS_VER=${CUBLAS_VER} && \
    pip install "polygraphy==0.49.9" && \
    bash tensorrt_llm/docker/common/install_mpi4py.sh

##############################################################################
##
## TRT-LLM wheel
##
##############################################################################

FROM trtllm_builder AS trtllm_wheel

ARG BUILD_WHEEL_ARGS="--clean --trt_root /usr/local/tensorrt --benchmarks"
ARG JOB_COUNT=32

WORKDIR /src/tensorrt_llm

COPY --from=trtllm_repo /src/tensorrt_llm .

RUN bash docker/common/install_base.sh && \
    bash docker/common/install_cmake.sh && \
    bash docker/common/install_ccache.sh

RUN python3 scripts/build_wheel.py --job_count $JOB_COUNT ${BUILD_WHEEL_ARGS}

##############################################################################
##
## Install TRT-LLM and vLLM
##
##############################################################################

FROM trtllm_builder AS trtllm_vllm_final

WORKDIR /opt/tensorrt_llm

# Copy Wheels
RUN --mount=type=bind,from=trtllm_wheel,source=/src/tensorrt_llm/build/,target=/tmp/tensorrt_llm/build/ \
    --mount=type=bind,from=vllm_wheel,source=/src/vllm/,target=/tmp/vllm/ \
    pip install --no-deps xgrammar==0.1.25 && \
    pip install /tmp/vllm/vllm*.whl && \
    pip install /tmp/tensorrt_llm/build/tensorrt_llm*.whl --extra-index-url https://pypi.nvidia.com && \
    ln -sv $(/usr/bin/python -c 'import site; print(f"{site.getsitepackages()[0]}/tensorrt_llm/libs")') lib && \
    test -f lib/libnvinfer_plugin_tensorrt_llm.so && \
    ln -sv lib/libnvinfer_plugin_tensorrt_llm.so lib/libnvinfer_plugin_tensorrt_llm.so.9 && \
    echo "/opt/tensorrt_llm/lib" > /etc/ld.so.conf.d/tensorrt_llm.conf && \
    ldconfig

WORKDIR /opt
